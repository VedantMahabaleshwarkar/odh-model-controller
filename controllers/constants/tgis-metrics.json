{
  "Number of incoming requests" : {
    "Graphs" : [
      {
        "Title": "Successful Requests",
        "Query": "sum(increase(tgi_request_success{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}]))"
      },
      {
        "Title": "Failed Requests",
        "Query": "sum(increase(tgi_request_failure{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}]))"
      }
    ]
  },
  "Mean Model Latency" : {
    "Graphs" : [
      {
        "Title": "Mean inference latency",
        "Query": "sum by (pod) (rate(tgi_request_inference_duration_sum{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}])) / sum by (pod) (rate(tgi_request_inference_duration_count{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[1m]))"
      },
      {
        "Title": "Mean request latency",
        "Query": "sum by (pod) (rate(tgi_request_duration_sum{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}])) / sum by (pod) (rate(tgi_request_duration_count{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[1m]))"
      }
    ]
  },
  "CPU usage" : {
    "Graphs" : [
      {
        "Title": "CPU usage",
        "Query": "sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace='${namespace}'}* on(namespace,pod) group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{namespace='${namespace}', workload=~'${model_name}-predictor-.*', workload_type=~'deployment'}) by (pod)"
      }
    ]
  },
  "Memory usage" : {
    "Graphs" : [
      {
        "Title": "CPU usage",
        "Query": "sum(container_memory_working_set_bytes{namespace='${namespace}', container!='', image!=''} * on(namespace,pod) group_left(workload, workload_type) namespace_workload_pod:kube_pod_owner:relabel{cluster='', namespace='${namespace}', workload=~'${model_name}-.*', workload_type=~'deployment'}) by (pod)"
      }
    ]
  }
}